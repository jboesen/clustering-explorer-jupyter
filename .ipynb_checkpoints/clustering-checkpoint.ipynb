{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import dtreeviz\n",
    "from ipywidgets import HBox, VBox, Layout, Output\n",
    "from IPython.display import display\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 (interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram\n",
    "from math import sqrt, ceil\n",
    "import plotly.express as px\n",
    "from plotly.graph_objs import FigureWidget, Scatter, Table\n",
    "def create_histograms(df=df, exclude_cols=['target', '_x', '_y'], legend=True):\n",
    "    curr_df = df.drop(exclude_cols, axis=1)\n",
    "    r = int(sqrt(len(curr_df.columns)))\n",
    "    c = ceil(len(curr_df.columns) / r)\n",
    "    # fig = make_subplots(rows=r+1, cols=c+1, column_width=[1/c for _ in range(c + 1)], horizontal_spacing=0.2)\n",
    "    fig = make_subplots(rows=r+1, cols=c+1)\n",
    "    col_num =0\n",
    "    max_cols = len(df.columns)\n",
    "    for i in range(1, r+1):\n",
    "        for j in range(1, c+1):\n",
    "            if col_num < max_cols:\n",
    "                fig.add_trace(go.Histogram(x=curr_df[curr_df.columns[col_num]], name=curr_df.columns[col_num]), row=i, col=j) \n",
    "                fig.add_annotation(xref=\"x domain\",yref=\"y domain\",x=0.5, y=1.2, showarrow=False,\n",
    "                       text=f\"<b>{curr_df.columns[col_num]}</b>\", row=i, col=j)\n",
    "            col_num += 1\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0))\n",
    "    # fig.update_layout(\n",
    "    #     legend=dict(\n",
    "    #     )\n",
    "    # )\n",
    "    fig.update_traces(showlegend=legend)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_cluster(df, x_cols):\n",
    "    # Split data into features and target\n",
    "    X = df[x_cols].values  # replace with the names of the columns you want to use as features\n",
    "    y = df['_selected'].values  # replace with the name of the target column you want to predict\n",
    "\n",
    "    # Create and fit a decision tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    feature_importances = clf.feature_importances_\n",
    "#     print(feature_importances, x_cols)\n",
    "    # Print the feature importances\n",
    "    # Combine feature names and importances into a list of tuples\n",
    "    feature_importances = list(zip(x_cols, feature_importances))\n",
    "\n",
    "    # Sort the list in descending order by feature importance\n",
    "    feature_importances_sorted = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Iterate over the sorted list and print out the feature names and importances\n",
    "    from ipywidgets import Output, VBox\n",
    "    print('Feature Importances in Decision Tree')\n",
    "    for feature_name, importance in feature_importances_sorted:\n",
    "        importance_percent = importance * 100\n",
    "        print(f\"{feature_name}: {importance_percent:.2f}%\")    \n",
    "    viz_model = dtreeviz.model(clf,\n",
    "                           X_train=X, y_train=y,\n",
    "                           feature_names=x_cols,\n",
    "                           target_name=['_selected'], class_names=[\"not selected\", \"selected\"])\n",
    "#     tree.plot_tree(clf,\n",
    "#        feature_names = x_cols, \n",
    "# #         feature_names = ['A', 'B', 'C', 'D'],\n",
    "#        class_names=['not selected', 'selected'],\n",
    "#        filled = True)\n",
    "#     print(type(viz_model))\n",
    "    print(type(viz_model))\n",
    "    out = viz_model.view(scale=0.8)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit decision tree to selected and not zselected points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8dd18822d740a5abe1ebe9ac7a51df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'opacity': 0.5},\n",
       "              'mode': 'markers',\n",
       "     â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances in Decision Tree\n",
      "petal length (cm): 51.52%\n",
      "sepal length (cm): 40.61%\n",
      "sepal width (cm): 7.87%\n",
      "petal width (cm): 0.00%\n",
      "<class 'dtreeviz.trees.DTreeVizAPI'>\n"
     ]
    }
   ],
   "source": [
    "def create_lasso(data=df, mode='table', exclude_cols=[]):\n",
    "    \"\"\"\n",
    "    Input: Datafame\n",
    "    Output: Plotly FigureWidget with lasso select tool\n",
    "    data: Pandas Dataframe of data\n",
    "    exclude_cols: columns to exclude\n",
    "    mode:\n",
    "     - 'table' shows a table of selected points\n",
    "     - 'histogram' shows an interactive histogram selected points\n",
    "     - 'explainer' predicts which factors lead to clustered selection\n",
    "    \"\"\"\n",
    "    IS_HIST = mode == 'histogram'\n",
    "    TOP_FACTORS = mode == 'explainer'\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(df)\n",
    "    pca_df = pd.DataFrame(pca.transform(df), columns=['_x', '_y'])\n",
    "    df['_x'] = pca_df['_x']\n",
    "    df['_y'] = pca_df['_y']\n",
    "\n",
    "    # TODO: default to lasso select\n",
    "    # data_name = f\"{df=}\".split('=')[0]\n",
    "    f = FigureWidget([Scatter(y = df[\"_x\"], x = df[\"_y\"], mode = 'markers')])\n",
    "    f.update_layout(dragmode='lasso')\n",
    "    f.layout.title = \"Data Lasso Scatterplot\"\n",
    "    scatter = f.data[0]\n",
    "    df.dropna()\n",
    "    exclude_cols.extend(['_x', '_y'])\n",
    "\n",
    "    N = len(df)\n",
    "    scatter.marker.opacity = 0.5\n",
    "    t, s = None, None\n",
    "    \n",
    "    if mode=='table':\n",
    "        # Create a table FigureWidget that updates on selection from points in the scatter plot of f\n",
    "        t = FigureWidget([Table(\n",
    "            header=dict(values=df.columns,\n",
    "                        fill = dict(color='#C2D4FF'),\n",
    "                        align = ['left'] * 5),\n",
    "\n",
    "            cells=dict(values=[df[col] for col in df.columns],\n",
    "                    fill = dict(color='#F5F8FF'),\n",
    "                    align = ['left'] * 5\n",
    "                    ))])\n",
    "    if IS_HIST:\n",
    "        hist = create_histograms(df, exclude_cols=exclude_cols, legend=True)\n",
    "        no_legend = create_histograms(df, exclude_cols=exclude_cols)\n",
    "        # t is for \"table\", but can also be where data is\n",
    "        t = go.FigureWidget(no_legend, )\n",
    "        t.layout.title = 'All Points'\n",
    "        # s is selected\n",
    "        s = go.FigureWidget(hist)\n",
    "        s.layout.title = 'Selected Points'\n",
    "    if TOP_FACTORS:\n",
    "        pass\n",
    "    def selection_fn(trace,points,selector):\n",
    "        nonlocal s\n",
    "        if mode=='table':\n",
    "            t.data[0].cells.values = [df.loc[points.point_inds][col] for col in df.columns]\n",
    "        if IS_HIST:\n",
    "            selected = df[df.index.isin(points.point_inds)]\n",
    "            new_charts = create_histograms(selected, exclude_cols=exclude_cols, legend=True)\n",
    "            s.data = []\n",
    "            s.add_traces(new_charts.data)\n",
    "        if TOP_FACTORS:\n",
    "            df['_selected'] = df.index.isin(points.point_inds)\n",
    "            x_cols = list(filter(lambda x: x not in exclude_cols and x != '_selected', df.columns))\n",
    "            s = explain_cluster(df, x_cols)\n",
    "            # t.data = []\n",
    "            # t.add_traces(decision_tree.data)            \n",
    "    scatter.on_selection(selection_fn)\n",
    "\n",
    "    # iplot({data : scatter.on_selection(selection_fn)})\n",
    "    print(s)\n",
    "    # Put everything together\n",
    "    if IS_HIST:\n",
    "        return VBox((f, s, t), layout=Layout(align_items='flex-start', margin='0px', justify_content='center'))\n",
    "    return VBox(tuple(x for x in [f, s, t] if x))\n",
    "\n",
    "create_lasso(mode='explainer', exclude_cols=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering-env",
   "language": "python",
   "name": "clustering-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3be008d9598bdeb156bf19ddb750f087ef8697cc8713cee29e62b7d60c55a336"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
